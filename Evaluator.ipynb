{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation and Comparison\n",
        "\n",
        "This notebook evaluates multiple trained models and compares them against a baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluate import evaluate\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set up the models you want to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_PATH = \"data/\"\n",
        "ASSETS_PATH = \"assets/\"\n",
        "\n",
        "# List of model names to evaluate (these should exist in assets/ directory)\n",
        "# first one will be the baseline\n",
        "MODEL_NAMES = [\n",
        "    \"logistic_regression_baseline\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run evaluation\n",
        "results_df = evaluate(DATA_PATH, MODEL_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretty Print Results with Baseline Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pretty_print_results(results_df, baseline_name, decimal_places=3):\n",
        "    \"\"\"\n",
        "    Pretty print evaluation results with baseline comparison.\n",
        "    \n",
        "    Args:\n",
        "        results_df: DataFrame with evaluation results\n",
        "        baseline_name: Name of the baseline model\n",
        "        decimal_places: Number of decimal places for rounding\n",
        "    \"\"\"\n",
        "    # Find baseline row\n",
        "    baseline_row = results_df[results_df['model_name'] == baseline_name]\n",
        "    \n",
        "    if len(baseline_row) == 0:\n",
        "        print(f\"Error: Baseline model '{baseline_name}' not found in results\")\n",
        "        return\n",
        "    \n",
        "    baseline_metrics = baseline_row.iloc[0]\n",
        "    \n",
        "    # Get numeric columns (excluding model_name)\n",
        "    numeric_cols = [col for col in results_df.columns if col != 'model_name']\n",
        "    \n",
        "    print(\"=\" * 100)\n",
        "    print(\"EVALUATION RESULTS WITH BASELINE COMPARISON\")\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"\\nBaseline Model: {baseline_name}\")\n",
        "    print(\"-\" * 100)\n",
        "    \n",
        "    # Display each model's results\n",
        "    for idx, row in results_df.iterrows():\n",
        "        model_name = row['model_name']\n",
        "        is_baseline = model_name == baseline_name\n",
        "        \n",
        "        print(f\"\\n{'> BASELINE <' if is_baseline else 'Model'}: {model_name}\")\n",
        "        print(\"-\" * 100)\n",
        "        \n",
        "        for col in numeric_cols:\n",
        "            value = row[col]\n",
        "            \n",
        "            # Skip loss and accuracy columns for percent difference calculation\n",
        "            if 'loss' in col.lower():\n",
        "                print(f\"  {col:40s}: {value:.{decimal_places}f}\")\n",
        "            elif 'accuracy' in col.lower() or 'precision' in col.lower() or 'recall' in col.lower():\n",
        "                baseline_value = baseline_metrics[col]\n",
        "                \n",
        "                if is_baseline:\n",
        "                    print(f\"  {col:40s}: {value:.{decimal_places}f}%\")\n",
        "                else:\n",
        "                    diff = value - baseline_value\n",
        "                    diff_percent = (diff / baseline_value * 100) if baseline_value != 0 else 0\n",
        "                    sign = \"+\" if diff >= 0 else \"\"\n",
        "                    print(f\"  {col:40s}: {value:.{decimal_places}f}% ({sign}{diff_percent:.{decimal_places}f}% vs baseline)\")\n",
        "            else:\n",
        "                print(f\"  {col:40s}: {value:.{decimal_places}f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display pretty results\n",
        "pretty_print_results(results_df, BASELINE_NAME)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
